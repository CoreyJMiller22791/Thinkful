{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "import spacy\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import gutenberg, stopwords\n",
    "from collections import Counter\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function for standard text cleaning.\n",
    "def text_cleaner(text):\n",
    "    # Visual inspection identifies a form of punctuation spaCy does not\n",
    "    # recognize: the double dash '--'.  Better get rid of it now!\n",
    "    text = re.sub(r'--',' ',text)\n",
    "    text = re.sub(\"[\\[].*?[\\]]\", \"\", text)\n",
    "    text = ' '.join(text.split())\n",
    "    return text\n",
    "    \n",
    "# Load and clean the data.\n",
    "persuasion = gutenberg.raw('austen-persuasion.txt')\n",
    "alice = gutenberg.raw('carroll-alice.txt')\n",
    "\n",
    "# The Chapter indicator is idiosyncratic\n",
    "persuasion = re.sub(r'Chapter \\d+', '', persuasion)\n",
    "alice = re.sub(r'CHAPTER .*', '', alice)\n",
    "    \n",
    "alice = text_cleaner(alice)\n",
    "persuasion = text_cleaner(persuasion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the cleaned novels. This can take a bit.\n",
    "nlp = spacy.load('en')\n",
    "alice_doc = nlp(alice)\n",
    "persuasion_doc = nlp(persuasion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34363"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(alice_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   0        1\n",
      "0  (Alice, was, beginning, to, get, very, tired, ...  Carroll\n",
      "1  (So, she, was, considering, in, her, own, mind...  Carroll\n",
      "2  (There, was, nothing, so, VERY, remarkable, in...  Carroll\n",
      "3                                      (Oh, dear, !)  Carroll\n",
      "4                         (I, shall, be, late, !, ')  Carroll\n",
      "(5318, 2)\n"
     ]
    }
   ],
   "source": [
    "# Group into sentences.\n",
    "alice_sents = [[sent, \"Carroll\"] for sent in alice_doc.sents]\n",
    "persuasion_sents = [[sent, \"Austen\"] for sent in persuasion_doc.sents]\n",
    "\n",
    "# Combine the sentences from the two novels into one data frame.\n",
    "sentences = pd.DataFrame(alice_sents + persuasion_sents)\n",
    "\n",
    "print(sentences.head())\n",
    "print(sentences.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "309\n"
     ]
    }
   ],
   "source": [
    "# Utility function to create a list of the 2000 most common words.\n",
    "def bag_of_words(text):\n",
    "    \n",
    "    # Filter out punctuation and stop words.\n",
    "    allwords = [token.lemma_\n",
    "                for token in text\n",
    "                if not token.is_punct\n",
    "                and not token.is_stop]\n",
    "    \n",
    "    # Return the most common words.\n",
    "    return [item[0] for item in Counter(allwords).most_common(200)]\n",
    "    \n",
    "\n",
    "# Creates a data frame with features for each word in our common word set.\n",
    "# Each value is the count of the times the word appears in each sentence.\n",
    "def bow_features(sentences, common_words):\n",
    "    T0=time.time()\n",
    "    # Scaffold the data frame and initialize counts to zero.\n",
    "    df = pd.DataFrame(columns=common_words)\n",
    "    df['text_sentence'] = sentences[0]\n",
    "    df['text_source'] = sentences[1]\n",
    "    df.loc[:, common_words] = 0\n",
    "    \n",
    "    # Process each row, counting the occurrence of words in each sentence.\n",
    "    t0=time.time()\n",
    "    for i, sentence in enumerate(df['text_sentence']):\n",
    "        \n",
    "        # Convert the sentence to lemmas, then filter out punctuation,\n",
    "        # stop words, and uncommon words.\n",
    "        words = (token.lemma_\n",
    "                 for token in sentence\n",
    "                 if (\n",
    "                     not token.is_punct\n",
    "                     and not token.is_stop\n",
    "                     and token.lemma_ in common_words\n",
    "                 ))\n",
    "        \n",
    "        # Populate the row with word counts.\n",
    "        for word in words:\n",
    "            df.loc[i, word] += 1\n",
    "        \n",
    "        # This counter is just to make sure the kernel didn't hang.\n",
    "        if i % 100 == 0:\n",
    "            print(\"Processing row {}\".format(i))\n",
    "            t1=time.time()\n",
    "            print('Time for {} rows = {:0.5f}s'.format(i, (t1-t0)))\n",
    "    T1 = time.time()\n",
    "    print('Total time = {0:0.5f}s'.format(T1-T0))\n",
    "    return df\n",
    "\n",
    "# Set up the bags.\n",
    "alicewords = bag_of_words(alice_doc)\n",
    "persuasionwords = bag_of_words(persuasion_doc)\n",
    "\n",
    "# Combine bags to create a set of unique words.\n",
    "common_words = set(alicewords + persuasionwords)\n",
    "print(len(common_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 0\n",
      "Time for 0 rows = 0.17154s\n",
      "Processing row 100\n",
      "Time for 100 rows = 9.29116s\n",
      "Processing row 200\n",
      "Time for 200 rows = 17.52628s\n",
      "Processing row 300\n",
      "Time for 300 rows = 25.49949s\n",
      "Processing row 400\n",
      "Time for 400 rows = 33.76852s\n",
      "Processing row 500\n",
      "Time for 500 rows = 40.23813s\n",
      "Processing row 600\n",
      "Time for 600 rows = 48.22478s\n",
      "Processing row 700\n",
      "Time for 700 rows = 55.44547s\n",
      "Processing row 800\n",
      "Time for 800 rows = 64.27077s\n",
      "Processing row 900\n",
      "Time for 900 rows = 71.85670s\n",
      "Processing row 1000\n",
      "Time for 1000 rows = 79.51190s\n",
      "Processing row 1100\n",
      "Time for 1100 rows = 87.07448s\n",
      "Processing row 1200\n",
      "Time for 1200 rows = 95.38172s\n",
      "Processing row 1300\n",
      "Time for 1300 rows = 101.58715s\n",
      "Processing row 1400\n",
      "Time for 1400 rows = 108.47380s\n",
      "Processing row 1500\n",
      "Time for 1500 rows = 115.56490s\n",
      "Processing row 1600\n",
      "Time for 1600 rows = 122.92627s\n",
      "Processing row 1700\n",
      "Time for 1700 rows = 132.39205s\n",
      "Processing row 1800\n",
      "Time for 1800 rows = 141.15434s\n",
      "Processing row 1900\n",
      "Time for 1900 rows = 150.84981s\n",
      "Processing row 2000\n",
      "Time for 2000 rows = 160.97342s\n",
      "Processing row 2100\n",
      "Time for 2100 rows = 168.51307s\n",
      "Processing row 2200\n",
      "Time for 2200 rows = 180.02565s\n",
      "Processing row 2300\n",
      "Time for 2300 rows = 190.44667s\n",
      "Processing row 2400\n",
      "Time for 2400 rows = 198.07232s\n",
      "Processing row 2500\n",
      "Time for 2500 rows = 205.06179s\n",
      "Processing row 2600\n",
      "Time for 2600 rows = 214.20567s\n",
      "Processing row 2700\n",
      "Time for 2700 rows = 223.27643s\n",
      "Processing row 2800\n",
      "Time for 2800 rows = 230.77063s\n",
      "Processing row 2900\n",
      "Time for 2900 rows = 242.66064s\n",
      "Processing row 3000\n",
      "Time for 3000 rows = 250.98485s\n",
      "Processing row 3100\n",
      "Time for 3100 rows = 258.82162s\n",
      "Processing row 3200\n",
      "Time for 3200 rows = 267.01284s\n",
      "Processing row 3300\n",
      "Time for 3300 rows = 274.87483s\n",
      "Processing row 3400\n",
      "Time for 3400 rows = 282.51041s\n",
      "Processing row 3500\n",
      "Time for 3500 rows = 289.80392s\n",
      "Processing row 3600\n",
      "Time for 3600 rows = 299.01332s\n",
      "Processing row 3700\n",
      "Time for 3700 rows = 307.36397s\n",
      "Processing row 3800\n",
      "Time for 3800 rows = 314.23361s\n",
      "Processing row 3900\n",
      "Time for 3900 rows = 320.53776s\n",
      "Processing row 4000\n",
      "Time for 4000 rows = 327.13612s\n",
      "Processing row 4100\n",
      "Time for 4100 rows = 334.44858s\n",
      "Processing row 4200\n",
      "Time for 4200 rows = 340.81755s\n",
      "Processing row 4300\n",
      "Time for 4300 rows = 346.43353s\n",
      "Processing row 4400\n",
      "Time for 4400 rows = 353.03389s\n",
      "Processing row 4500\n",
      "Time for 4500 rows = 359.15552s\n",
      "Processing row 4600\n",
      "Time for 4600 rows = 366.54477s\n",
      "Processing row 4700\n",
      "Time for 4700 rows = 374.84317s\n",
      "Processing row 4800\n",
      "Time for 4800 rows = 383.48301s\n",
      "Processing row 4900\n",
      "Time for 4900 rows = 389.30097s\n",
      "Processing row 5000\n",
      "Time for 5000 rows = 397.57025s\n",
      "Processing row 5100\n",
      "Time for 5100 rows = 404.11480s\n",
      "Processing row 5200\n",
      "Time for 5200 rows = 410.22843s\n",
      "Processing row 5300\n",
      "Time for 5300 rows = 417.77427s\n",
      "Total time = 419.30470s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cousin</th>\n",
       "      <th>oh</th>\n",
       "      <th>country</th>\n",
       "      <th>if</th>\n",
       "      <th>thing</th>\n",
       "      <th>try</th>\n",
       "      <th>pass</th>\n",
       "      <th>mouth</th>\n",
       "      <th>world</th>\n",
       "      <th>mouse</th>\n",
       "      <th>...</th>\n",
       "      <th>manage</th>\n",
       "      <th>visit</th>\n",
       "      <th>woman</th>\n",
       "      <th>week</th>\n",
       "      <th>attention</th>\n",
       "      <th>beautiful</th>\n",
       "      <th>why</th>\n",
       "      <th>daughter</th>\n",
       "      <th>text_sentence</th>\n",
       "      <th>text_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(Alice, was, beginning, to, get, very, tired, ...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(So, she, was, considering, in, her, own, mind...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(There, was, nothing, so, VERY, remarkable, in...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(Oh, dear, !)</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(I, shall, be, late, !, ')</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 311 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  cousin oh country if thing try pass mouth world mouse     ...     manage  \\\n",
       "0      0  0       0  0     0   0    0     0     0     0     ...          0   \n",
       "1      0  0       0  0     0   0    0     0     0     0     ...          0   \n",
       "2      0  1       0  0     0   0    0     0     0     0     ...          0   \n",
       "3      0  1       0  0     0   0    0     0     0     0     ...          0   \n",
       "4      0  0       0  0     0   0    0     0     0     0     ...          0   \n",
       "\n",
       "  visit woman week attention beautiful why daughter  \\\n",
       "0     0     0    0         0         0   0        0   \n",
       "1     0     0    0         0         0   0        0   \n",
       "2     0     0    0         0         0   0        0   \n",
       "3     0     0    0         0         0   0        0   \n",
       "4     0     0    0         0         0   0        0   \n",
       "\n",
       "                                       text_sentence text_source  \n",
       "0  (Alice, was, beginning, to, get, very, tired, ...     Carroll  \n",
       "1  (So, she, was, considering, in, her, own, mind...     Carroll  \n",
       "2  (There, was, nothing, so, VERY, remarkable, in...     Carroll  \n",
       "3                                      (Oh, dear, !)     Carroll  \n",
       "4                         (I, shall, be, late, !, ')     Carroll  \n",
       "\n",
       "[5 rows x 311 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create our data frame with features. This can take a while to run.\n",
    "\n",
    "word_counts = bow_features(sentences, common_words)\n",
    "word_counts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With 2000 common words the function takes too long\n",
    "\n",
    "Processing row 0\n",
    "Time for 0 rows = 10.17418s\n",
    "Processing row 100\n",
    "Time for 100 rows = 548.92410s\n",
    "Processing row 200\n",
    "Time for 200 rows = 1028.07908s\n",
    "Processing row 300\n",
    "Time for 300 rows = 1487.26214s\n",
    "Processing row 400\n",
    "Time for 400 rows = 1941.50908s\n",
    "Processing row 500\n",
    "Time for 500 rows = 2401.70543s\n",
    "Processing row 600\n",
    "Time for 600 rows = 3042.22495s\n",
    "Processing row 700\n",
    "Time for 700 rows = 3443.65342s\n",
    "Processing row 800\n",
    "Time for 800 rows = 3822.90835s\n",
    "Processing row 900\n",
    "Time for 900 rows = 4141.80880s\n",
    "Processing row 1000\n",
    "Time for 1000 rows = 4521.30246s\n",
    "Processing row 1100\n",
    "Time for 1100 rows = 4940.44947s\n",
    "Processing row 1200\n",
    "Time for 1200 rows = 5361.15024s\n",
    "Processing row 1300\n",
    "Time for 1300 rows = 5727.72254s\n",
    "Processing row 1400\n",
    "Time for 1400 rows = 6130.96701s\n",
    "Processing row 1500\n",
    "Time for 1500 rows = 6499.83867s\n",
    "Processing row 1600\n",
    "Time for 1600 rows = 7209.84054s\n",
    "Processing row 1700\n",
    "Time for 1700 rows = 8593.04145s\n",
    "Processing row 1800\n",
    "Time for 1800 rows = 10007.88465s\n",
    "Processing row 1900\n",
    "Time for 1900 rows = 11400.94565s\n",
    "Processing row 2000\n",
    "Time for 2000 rows = 12996.87139s\n",
    "Processing row 2100\n",
    "Time for 2100 rows = 13917.08054s\n",
    "Processing row 2200\n",
    "Time for 2200 rows = 15433.19193s\n",
    "Processing row 2300\n",
    "Time for 2300 rows = 16726.30992s\n",
    "Processing row 2400\n",
    "Time for 2400 rows = 17762.62421s\n",
    "Processing row 2500\n",
    "Time for 2500 rows = 18690.94225s\n",
    "Processing row 2600\n",
    "Time for 2600 rows = 19865.10566s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.961128526645768\n",
      "\n",
      "Test set score: 0.8782894736842105\n"
     ]
    }
   ],
   "source": [
    "from sklearn import ensemble\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "rfc = ensemble.RandomForestClassifier()\n",
    "Y = word_counts['text_source']\n",
    "X = np.array(word_counts.drop(['text_sentence','text_source'], 1))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    Y,\n",
    "                                                    test_size=0.4,\n",
    "                                                    random_state=0)\n",
    "train = rfc.fit(X_train, y_train)\n",
    "\n",
    "print('Training set score:', rfc.score(X_train, y_train))\n",
    "print('\\nTest set score:', rfc.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3190, 309) (3190,)\n",
      "Training set score: 0.9200626959247649\n",
      "\n",
      "Test set score: 0.9041353383458647\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression()\n",
    "train = lr.fit(X_train, y_train)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print('Training set score:', lr.score(X_train, y_train))\n",
    "print('\\nTest set score:', lr.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.8836990595611285\n",
      "\n",
      "Test set score: 0.8740601503759399\n"
     ]
    }
   ],
   "source": [
    "clf = ensemble.GradientBoostingClassifier()\n",
    "train = clf.fit(X_train, y_train)\n",
    "\n",
    "print('Training set score:', clf.score(X_train, y_train))\n",
    "print('\\nTest set score:', clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emma Woodhouse, handsome, clever, and rich, with a comfortable home and happy disposition, seemed to\n"
     ]
    }
   ],
   "source": [
    "# Clean the Emma data.\n",
    "emma = gutenberg.raw('austen-emma.txt')\n",
    "emma = re.sub(r'VOLUME \\w+', '', emma)\n",
    "emma = re.sub(r'CHAPTER \\w+', '', emma)\n",
    "emma = text_cleaner(emma)\n",
    "print(emma[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse our cleaned data.\n",
    "emma_doc = nlp(emma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group into sentences.\n",
    "persuasion_sents = [[sent, \"Austen\"] for sent in persuasion_doc.sents]\n",
    "emma_sents = [[sent, \"Austen\"] for sent in emma_doc.sents]\n",
    "\n",
    "# Emma is quite long, let's cut it down to the same length as Alice.\n",
    "emma_sents = emma_sents[0:len(alice_sents)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 0\n",
      "Time for 0 rows = 0.04289s\n",
      "Processing row 100\n",
      "Time for 100 rows = 2.37203s\n",
      "Processing row 200\n",
      "Time for 200 rows = 5.38755s\n",
      "Processing row 300\n",
      "Time for 300 rows = 8.90265s\n",
      "Processing row 400\n",
      "Time for 400 rows = 11.56865s\n",
      "Processing row 500\n",
      "Time for 500 rows = 13.62802s\n",
      "Processing row 600\n",
      "Time for 600 rows = 15.74547s\n",
      "Processing row 700\n",
      "Time for 700 rows = 17.92800s\n",
      "Processing row 800\n",
      "Time for 800 rows = 19.94725s\n",
      "Processing row 900\n",
      "Time for 900 rows = 22.04791s\n",
      "Processing row 1000\n",
      "Time for 1000 rows = 24.24186s\n",
      "Processing row 1100\n",
      "Time for 1100 rows = 26.38671s\n",
      "Processing row 1200\n",
      "Time for 1200 rows = 28.94586s\n",
      "Processing row 1300\n",
      "Time for 1300 rows = 30.49934s\n",
      "Processing row 1400\n",
      "Time for 1400 rows = 32.12400s\n",
      "Processing row 1500\n",
      "Time for 1500 rows = 34.22155s\n",
      "Processing row 1600\n",
      "Time for 1600 rows = 36.89616s\n",
      "Total time = 38.60148s\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# Build a new Bag of Words data frame for Emma word counts.\n",
    "# We'll use the same common words from Alice and Persuasion.\n",
    "emma_sentences = pd.DataFrame(emma_sents)\n",
    "emma_bow = bow_features(emma_sentences, common_words)\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set score: 0.6823266219239373\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>Austen</th>\n",
       "      <th>Carroll</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Austen</th>\n",
       "      <td>1552</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Carroll</th>\n",
       "      <td>735</td>\n",
       "      <td>278</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0    Austen  Carroll\n",
       "row_0                   \n",
       "Austen     1552      117\n",
       "Carroll     735      278"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we can model it!\n",
    "# Let's use logistic regression again.\n",
    "\n",
    "# Combine the Emma sentence data with the Alice data from the test set.\n",
    "X_Emma_test = np.concatenate((\n",
    "    X_train[y_train[y_train=='Carroll'].index],\n",
    "    emma_bow.drop(['text_sentence','text_source'], 1)\n",
    "), axis=0)\n",
    "y_Emma_test = pd.concat([y_train[y_train=='Carroll'],\n",
    "                         pd.Series(['Austen'] * emma_bow.shape[0])])\n",
    "\n",
    "# Model.\n",
    "print('\\nTest set score:', lr.score(X_Emma_test, y_Emma_test))\n",
    "lr_Emma_predicted = lr.predict(X_Emma_test)\n",
    "pd.crosstab(y_Emma_test, lr_Emma_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge 0: See what we can do to improve LogReg test score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ideas: \n",
    "- other modeling techniques (SVM?)\n",
    "- make more features (POS, grammar, phrases, etc)\n",
    "- sentence level features: (number of words, amount of punctuation)\n",
    "- contextual information: (length of previous and next sentence, words repeated from one sentence to the next, etc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the parts of speech\n",
    "def pos(df):\n",
    "    # initialize empty list to collect unique keys and values\n",
    "    parts_of_speech = []\n",
    "    dicts = []\n",
    "    \n",
    "    # get the sentences from df to find part of speech\n",
    "    for sentence in df['text_sentence']:\n",
    "        p_o_s = dict(Counter([token.pos_ for token in sentence]))\n",
    "        dicts.append(p_o_s)\n",
    "        for label in p_o_s:\n",
    "            parts_of_speech.append(label)\n",
    "            \n",
    "    # get the unique values for each part of speech\n",
    "    labels_pos = np.unique(parts_of_speech)\n",
    "\n",
    "    # dataframe to store values\n",
    "    count_df = pd.DataFrame(dicts, columns=labels_pos)\n",
    "    \n",
    "    # fill nan with 0\n",
    "    count_df.fillna(0,inplace=True)\n",
    "    \n",
    "    # concatenate the old dataframe with parts of speech\n",
    "    fin_df=pd.concat([df,count_df],1)\n",
    "    return fin_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  cousin oh country if thing try pass mouth world mouse ...   DET INTJ  NOUN  \\\n",
      "0      0  0       0  0     0   0    0     0     0     0 ...   5.0  0.0  12.0   \n",
      "1      0  0       0  0     0   0    0     0     0     0 ...   6.0  0.0   8.0   \n",
      "2      0  1       0  0     0   0    0     0     0     0 ...   3.0  2.0   2.0   \n",
      "3      0  1       0  0     0   0    0     0     0     0 ...   0.0  2.0   0.0   \n",
      "4      0  0       0  0     0   0    0     0     0     0 ...   0.0  0.0   0.0   \n",
      "\n",
      "   NUM PART PRON PROPN PUNCT  VERB    X  \n",
      "0  0.0  2.0  3.0   2.0  10.0  13.0  0.0  \n",
      "1  0.0  1.0  4.0   2.0   7.0  11.0  0.0  \n",
      "2  0.0  1.0  2.0   2.0   4.0   5.0  0.0  \n",
      "3  0.0  0.0  0.0   0.0   1.0   0.0  0.0  \n",
      "4  0.0  0.0  1.0   0.0   2.0   2.0  0.0  \n",
      "\n",
      "[5 rows x 325 columns]\n"
     ]
    }
   ],
   "source": [
    "# add parts of speech count to dataframe\n",
    "df = pos(word_counts)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# add a word count for each sentence\n",
    "def num_of_words(df):\n",
    "    \n",
    "    num_words = []\n",
    "    for i, sentence in enumerate(df['text_sentence']):\n",
    "        counts = [token.text for token in sentence if not token.is_punct]\n",
    "        num_words.append(len(counts))\n",
    "    df['num_words'] = num_words\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3633    1.0\n",
      "3850    1.0\n",
      "Name: X, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df = num_of_words(df)\n",
    "#print(df.head())\n",
    "print(df.X[df.X>0])\n",
    "df = df.drop('X',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3190, 323) (3190,)\n",
      "Training set score: 0.9225705329153605\n",
      "\n",
      "Test set score: 0.9130639097744361\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(C=1)\n",
    "Y = df['text_source']\n",
    "X = np.array(df.drop(['text_sentence','text_source'], 1))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    Y,\n",
    "                                                    test_size=0.4,\n",
    "                                                    random_state=0)\n",
    "\n",
    "train = lr.fit(X_train, y_train)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print('Training set score:', lr.score(X_train, y_train))\n",
    "print('\\nTest set score:', lr.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3190, 323) (3190,)\n",
      "Training set score: 0.9244514106583072\n",
      "\n",
      "Test set score: 0.9116541353383458\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc = SVC(kernel='linear', C=.7)\n",
    "Y = df['text_source']\n",
    "X = df.drop(['text_sentence','text_source'], 1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    Y,\n",
    "                                                    test_size=0.4,\n",
    "                                                    random_state=0)\n",
    "\n",
    "train = svc.fit(X_train, y_train)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print('Training set score:', svc.score(X_train, y_train))\n",
    "print('\\nTest set score:', svc.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3190, 323) (3190,)\n",
      "Training set score: 0.8840125391849529\n",
      "\n",
      "Test set score: 0.8773496240601504\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "bnb = BernoulliNB()\n",
    "Y = df['text_source']\n",
    "X = np.array(df.drop(['text_sentence','text_source'], 1))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    Y,\n",
    "                                                    test_size=0.4,\n",
    "                                                    random_state=0)\n",
    "\n",
    "train = bnb.fit(X_train, y_train)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print('Training set score:', bnb.score(X_train, y_train))\n",
    "print('\\nTest set score:', bnb.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  cousin oh country if thing try pass mouth world mouse    ...     DET INTJ  \\\n",
      "0      0  0       0  0     0   0    0     0     1     0    ...     4.0  0.0   \n",
      "1      0  0       0  0     0   0    0     0     0     0    ...     4.0  0.0   \n",
      "2      0  0       0  0     0   0    0     0     0     0    ...     3.0  0.0   \n",
      "3      0  0       0  0     0   0    0     0     0     0    ...     3.0  0.0   \n",
      "4      0  0       0  0     0   0    0     0     0     0    ...     0.0  0.0   \n",
      "\n",
      "  NOUN  NUM PART PRON PROPN PUNCT VERB num_words  \n",
      "0  6.0  2.0  2.0  1.0   2.0   8.0  6.0        41  \n",
      "1  8.0  1.0  1.0  1.0   0.0   5.0  3.0        33  \n",
      "2  9.0  0.0  1.0  1.0   0.0   3.0  8.0        41  \n",
      "3  5.0  1.0  1.0  0.0   5.0   4.0  2.0        27  \n",
      "4  0.0  0.0  0.0  1.0   0.0   0.0  1.0         2  \n",
      "\n",
      "[5 rows x 325 columns]\n",
      "(1669, 325)\n",
      "(5318, 325)\n"
     ]
    }
   ],
   "source": [
    "emma_df = pd.DataFrame()\n",
    "emma_df = pos(emma_bow)\n",
    "emma_df = num_of_words(emma_df)\n",
    "print(emma_df.head())\n",
    "print(emma_df.shape)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the Emma sentence data with the Alice data from the test set.\n",
    "alice_train = X_train[y_train[y_train=='Carroll'].index]\n",
    "emma_data = emma_df.drop(['text_sentence','text_source'], 1)\n",
    "X_Emma_test = np.concatenate([alice_train, emma_data], axis=0)\n",
    "y_Emma_test = pd.concat([y_train[y_train=='Carroll'],\n",
    "                         pd.Series(['Austen'] * emma_df.shape[0])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set score: 0.680089485458613\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>Austen</th>\n",
       "      <th>Carroll</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Austen</th>\n",
       "      <td>1532</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Carroll</th>\n",
       "      <td>721</td>\n",
       "      <td>292</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0    Austen  Carroll\n",
       "row_0                   \n",
       "Austen     1532      137\n",
       "Carroll     721      292"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model.\n",
    "print('\\nTest set score:', lr.score(X_Emma_test, y_Emma_test))\n",
    "lr_Emma_predicted = lr.predict(X_Emma_test)\n",
    "pd.crosstab(y_Emma_test, lr_Emma_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try new books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['austen-emma.txt', 'austen-persuasion.txt', 'austen-sense.txt', 'bible-kjv.txt', 'blake-poems.txt', 'bryant-stories.txt', 'burgess-busterbrown.txt', 'carroll-alice.txt', 'chesterton-ball.txt', 'chesterton-brown.txt', 'chesterton-thursday.txt', 'edgeworth-parents.txt', 'melville-moby_dick.txt', 'milton-paradise.txt', 'shakespeare-caesar.txt', 'shakespeare-hamlet.txt', 'shakespeare-macbeth.txt', 'whitman-leaves.txt']\n"
     ]
    }
   ],
   "source": [
    "print(gutenberg.fileids())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words in Moby Dick: 260819\n",
      "Number of Characters in Moby Dick 1242990\n",
      "Number of Characters in Alice 144395\n",
      "Call me Ishmael. Some years ago never mind how long precisely having little or no money in my purse,\n",
      "Processing row 0\n",
      "Time for 0 rows = 0.01562s\n",
      "Processing row 100\n",
      "Time for 100 rows = 0.87128s\n",
      "Processing row 200\n",
      "Time for 200 rows = 1.60265s\n",
      "Processing row 300\n",
      "Time for 300 rows = 2.62646s\n",
      "Processing row 400\n",
      "Time for 400 rows = 3.66332s\n",
      "Processing row 500\n",
      "Time for 500 rows = 4.60979s\n",
      "Processing row 600\n",
      "Time for 600 rows = 5.45877s\n",
      "Processing row 700\n",
      "Time for 700 rows = 6.20634s\n",
      "Processing row 800\n",
      "Time for 800 rows = 7.06966s\n",
      "Processing row 900\n",
      "Time for 900 rows = 8.07613s\n",
      "Processing row 1000\n",
      "Time for 1000 rows = 8.99900s\n",
      "Processing row 1100\n",
      "Time for 1100 rows = 9.82930s\n",
      "Total time = 10.67689s\n"
     ]
    }
   ],
   "source": [
    "# Clean the Moby Dick data.\n",
    "melville = gutenberg.raw('melville-moby_dick.txt')\n",
    "num_chars = len(gutenberg.raw('melville-moby_dick.txt'))\n",
    "num_words = len(gutenberg.words('melville-moby_dick.txt'))\n",
    "alice_char = len(gutenberg.raw('carroll-alice.txt'))\n",
    "print('Number of words in Moby Dick:',num_words)\n",
    "print('Number of Characters in Moby Dick', num_chars)\n",
    "print('Number of Characters in Alice', alice_char)\n",
    "melville = re.sub(r'VOLUME \\w+', '', melville)\n",
    "melville = re.sub(r'CHAPTER \\w+', '', melville)\n",
    "melville = text_cleaner(melville)\n",
    "\n",
    "# Moby dick is too large to tokenize- sample down same size as alice\n",
    "start = 20919\n",
    "end = 20919+alice_char\n",
    "melville = melville[start:end]\n",
    "print(melville[:100])\n",
    "\n",
    "# Parse our cleaned data.\n",
    "melville_doc = nlp(melville)\n",
    "\n",
    "# Get sentences\n",
    "melville_sents = [[sent, \"Melville\"] for sent in melville_doc.sents]\n",
    "melville_sentences = pd.DataFrame(melville_sents)\n",
    "\n",
    "# Get bag of words\n",
    "melville_bow = bow_features(melville_sentences, common_words)\n",
    "\n",
    "# Add additional features\n",
    "melville_df = pd.DataFrame()\n",
    "melville_df = pos(melville_bow)\n",
    "melville_df = num_of_words(melville_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alice in wonderland vs moby dick\n",
    "alice_train = X_train[y_train[y_train=='Carroll'].index]\n",
    "melville_data = melville_df.drop(['text_sentence','text_source'], 1)\n",
    "X_Melville_test = np.concatenate([alice_train, melville_data], axis=0)\n",
    "y_Melville_test = pd.concat([y_train[y_train=='Carroll'],\n",
    "                         pd.Series(['Melville'] * melville_df.shape[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([1300,  422, 1182,  998,  935, 1292, 1504,  249,  305,  273,\n",
      "            ...\n",
      "             544,  423,  659,  797,  755,   99,  537,  705, 1033, 1653],\n",
      "           dtype='int64', length=1013)\n"
     ]
    }
   ],
   "source": [
    "print(y_train[y_train=='Carroll'].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set score: 0.1343146274149034\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>Austen</th>\n",
       "      <th>Carroll</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Carroll</th>\n",
       "      <td>721</td>\n",
       "      <td>292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Melville</th>\n",
       "      <td>921</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0     Austen  Carroll\n",
       "row_0                    \n",
       "Carroll      721      292\n",
       "Melville     921      240"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model.\n",
    "print('\\nTest set score:', lr.score(X_Melville_test, y_Melville_test))\n",
    "lr_Melville_predicted = lr.predict(X_Melville_test)\n",
    "pd.crosstab(y_Melville_test, lr_Melville_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Carroll' 'Austen' 'Austen' ... 'Austen' 'Carroll' 'Austen']\n"
     ]
    }
   ],
   "source": [
    "print(lr_Melville_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 3709 is out of bounds for axis 0 with size 3190",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-287-ee353fafbb0a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# persuasion vs moby dick\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mpersuasion_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m'Austen'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mmelville_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmelville_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'text_sentence'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'text_source'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mX_Melville_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpersuasion_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmelville_data\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m y_Melville_test = pd.concat([y_train[y_train=='Austen'],\n",
      "\u001b[1;31mIndexError\u001b[0m: index 3709 is out of bounds for axis 0 with size 3190"
     ]
    }
   ],
   "source": [
    "# persuasion vs moby dick\n",
    "persuasion_train = X_train[y_train[y_train=='Austen'].index]\n",
    "melville_data = melville_df.drop(['text_sentence','text_source'], 1)\n",
    "X_Melville_test = np.concatenate([persuasion_train, melville_data], axis=0)\n",
    "y_Melville_test = pd.concat([y_train[y_train=='Austen'],\n",
    "                         pd.Series(['Melville'] * melville_df.shape[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set score: 0.4661473936488916\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>Austen</th>\n",
       "      <th>Carroll</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Austen</th>\n",
       "      <td>1556</td>\n",
       "      <td>621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Melville</th>\n",
       "      <td>921</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0     Austen  Carroll\n",
       "row_0                    \n",
       "Austen      1556      621\n",
       "Melville     921      240"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model.\n",
    "print('\\nTest set score:', lr.score(X_Melville_test, y_Melville_test))\n",
    "lr_Melville_predicted = lr.predict(X_Melville_test)\n",
    "pd.crosstab(y_Melville_test, lr_Melville_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Carroll' 'Austen' 'Austen' ... 'Austen' 'Carroll' 'Austen']\n"
     ]
    }
   ],
   "source": [
    "print(lr_Melville_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predicted author is always going to be Austen or Carroll because the data was trained on Alice in Wonderland (Lewis Carroll) and Persuasion (Jane Austen).\n",
    "\n",
    "Also, index for AUSTEN is out of range.  The index for Carroll comes first due to how the data was created. Not sure if data is matched appropriately when testing the EMMA data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3190, 323)\n",
      "1300    Carroll\n",
      "2125     Austen\n",
      "3709     Austen\n",
      "3244     Austen\n",
      "422     Carroll\n",
      "3515     Austen\n",
      "1182    Carroll\n",
      "998     Carroll\n",
      "2466     Austen\n",
      "4637     Austen\n",
      "935     Carroll\n",
      "2952     Austen\n",
      "1292    Carroll\n",
      "2730     Austen\n",
      "4555     Austen\n",
      "3579     Austen\n",
      "4179     Austen\n",
      "1504    Carroll\n",
      "3138     Austen\n",
      "2719     Austen\n",
      "4024     Austen\n",
      "249     Carroll\n",
      "3521     Austen\n",
      "305     Carroll\n",
      "273     Carroll\n",
      "3978     Austen\n",
      "3559     Austen\n",
      "2982     Austen\n",
      "4878     Austen\n",
      "1473    Carroll\n",
      "         ...   \n",
      "423     Carroll\n",
      "3219     Austen\n",
      "659     Carroll\n",
      "797     Carroll\n",
      "755     Carroll\n",
      "2008     Austen\n",
      "99      Carroll\n",
      "2496     Austen\n",
      "1871     Austen\n",
      "2046     Austen\n",
      "4851     Austen\n",
      "5072     Austen\n",
      "2163     Austen\n",
      "2893     Austen\n",
      "537     Carroll\n",
      "1701     Austen\n",
      "2897     Austen\n",
      "2222     Austen\n",
      "2135     Austen\n",
      "2599     Austen\n",
      "705     Carroll\n",
      "3468     Austen\n",
      "4373     Austen\n",
      "1033    Carroll\n",
      "4859     Austen\n",
      "4931     Austen\n",
      "3264     Austen\n",
      "1653    Carroll\n",
      "2607     Austen\n",
      "2732     Austen\n",
      "Name: text_source, Length: 3190, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "#print([y_train[y_train=='Austen']])\n",
    "#print([y_train[y_train=='Carroll']])\n",
    "print(y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       Carroll\n",
      "1        Austen\n",
      "2        Austen\n",
      "3        Austen\n",
      "4       Carroll\n",
      "5        Austen\n",
      "6       Carroll\n",
      "7       Carroll\n",
      "8        Austen\n",
      "9        Austen\n",
      "10      Carroll\n",
      "11       Austen\n",
      "12      Carroll\n",
      "13       Austen\n",
      "14       Austen\n",
      "15       Austen\n",
      "16       Austen\n",
      "17      Carroll\n",
      "18       Austen\n",
      "19       Austen\n",
      "20       Austen\n",
      "21      Carroll\n",
      "22       Austen\n",
      "23      Carroll\n",
      "24      Carroll\n",
      "25       Austen\n",
      "26       Austen\n",
      "27       Austen\n",
      "28       Austen\n",
      "29      Carroll\n",
      "         ...   \n",
      "3160    Carroll\n",
      "3161     Austen\n",
      "3162    Carroll\n",
      "3163    Carroll\n",
      "3164    Carroll\n",
      "3165     Austen\n",
      "3166    Carroll\n",
      "3167     Austen\n",
      "3168     Austen\n",
      "3169     Austen\n",
      "3170     Austen\n",
      "3171     Austen\n",
      "3172     Austen\n",
      "3173     Austen\n",
      "3174    Carroll\n",
      "3175     Austen\n",
      "3176     Austen\n",
      "3177     Austen\n",
      "3178     Austen\n",
      "3179     Austen\n",
      "3180    Carroll\n",
      "3181     Austen\n",
      "3182     Austen\n",
      "3183    Carroll\n",
      "3184     Austen\n",
      "3185     Austen\n",
      "3186     Austen\n",
      "3187    Carroll\n",
      "3188     Austen\n",
      "3189     Austen\n",
      "Name: text_source, Length: 3190, dtype: object\n",
      "[Int64Index([   1,    2,    3,    5,    8,    9,   11,   13,   14,   15,\n",
      "            ...\n",
      "            3177, 3178, 3179, 3181, 3182, 3184, 3185, 3186, 3188, 3189],\n",
      "           dtype='int64', length=2177)]\n",
      "[Int64Index([   0,    4,    6,    7,   10,   12,   17,   21,   23,   24,\n",
      "            ...\n",
      "            3156, 3160, 3162, 3163, 3164, 3166, 3174, 3180, 3183, 3187],\n",
      "           dtype='int64', length=1013)]\n"
     ]
    }
   ],
   "source": [
    "y_train = y_train.reset_index(drop=True)\n",
    "print(y_train)\n",
    "print([y_train[y_train=='Austen'].index])\n",
    "print([y_train[y_train=='Carroll'].index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now data should match X_train correctly. Instead of using the original indices from the full dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the Emma sentence data with the Alice data from the test set.\n",
    "alice_train = X_train[y_train[y_train=='Carroll'].index]\n",
    "emma_data = emma_df.drop(['text_sentence','text_source'], 1)\n",
    "X_Emma_test = np.concatenate([alice_train, emma_data], axis=0)\n",
    "y_Emma_test = pd.concat([y_train[y_train=='Carroll'],\n",
    "                         pd.Series(['Austen'] * emma_df.shape[0])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set score: 0.8791946308724832\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>Austen</th>\n",
       "      <th>Carroll</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Austen</th>\n",
       "      <td>1532</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Carroll</th>\n",
       "      <td>187</td>\n",
       "      <td>826</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0    Austen  Carroll\n",
       "row_0                   \n",
       "Austen     1532      137\n",
       "Carroll     187      826"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model.\n",
    "print('\\nTest set score:', lr.score(X_Emma_test, y_Emma_test))\n",
    "lr_Emma_predicted = lr.predict(X_Emma_test)\n",
    "pd.crosstab(y_Emma_test, lr_Emma_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alice in wonderland vs moby dick\n",
    "alice_train = X_train[y_train[y_train=='Carroll'].index]\n",
    "melville_data = melville_df.drop(['text_sentence','text_source'], 1)\n",
    "X_Melville_test = np.concatenate([alice_train, melville_data], axis=0)\n",
    "y_Melville_test = pd.concat([y_train[y_train=='Carroll'],\n",
    "                         pd.Series(['Melville'] * melville_df.shape[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set score: 0.37994480220791166\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>Austen</th>\n",
       "      <th>Carroll</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Carroll</th>\n",
       "      <td>187</td>\n",
       "      <td>826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Melville</th>\n",
       "      <td>921</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0     Austen  Carroll\n",
       "row_0                    \n",
       "Carroll      187      826\n",
       "Melville     921      240"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model.\n",
    "print('\\nTest set score:', lr.score(X_Melville_test, y_Melville_test))\n",
    "lr_Melville_predicted = lr.predict(X_Melville_test)\n",
    "pd.crosstab(y_Melville_test, lr_Melville_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "# persuasion vs moby dick\n",
    "persuasion_train = X_train[y_train[y_train=='Austen'].index]\n",
    "melville_data = melville_df.drop(['text_sentence','text_source'], 1)\n",
    "X_Melville_test = np.concatenate([persuasion_train, melville_data], axis=0)\n",
    "y_Melville_test = pd.concat([y_train[y_train=='Austen'],\n",
    "                         pd.Series(['Melville'] * melville_df.shape[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set score: 0.634212103055722\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>Austen</th>\n",
       "      <th>Carroll</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Austen</th>\n",
       "      <td>2117</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Melville</th>\n",
       "      <td>921</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0     Austen  Carroll\n",
       "row_0                    \n",
       "Austen      2117       60\n",
       "Melville     921      240"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model.\n",
    "print('\\nTest set score:', lr.score(X_Melville_test, y_Melville_test))\n",
    "lr_Melville_predicted = lr.predict(X_Melville_test)\n",
    "pd.crosstab(y_Melville_test, lr_Melville_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I don't believe I am testing the correctly.  The number of Melvile goods and bad is not changing, most likely because the model is trained on different authors.  I think to continue to use this mess here I would need to call Melville the author I have replaced with him to test against the other. For example, I would have to label Melville as Carroll to test against austen and vice versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
