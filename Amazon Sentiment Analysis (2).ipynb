{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gzip\n",
    "import string\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction import text\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(path):\n",
    "    g = gzip.open(path, 'rb')\n",
    "    for l in g:\n",
    "        yield eval(l)\n",
    "\n",
    "def getDF(path):\n",
    "    i = 0\n",
    "    df = {}\n",
    "    for d in parse(path):\n",
    "        df[i] = d\n",
    "        i += 1\n",
    "    return pd.DataFrame.from_dict(df, orient='index')\n",
    "\n",
    "df = getDF('reviews_Automotive_5.json.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       reviewerID        asin     reviewerName   helpful  \\\n",
      "0  A3F73SC1LY51OO  B00002243X  Alan Montgomery    [4, 4]   \n",
      "1  A20S66SKYXULG2  B00002243X         alphonse    [1, 1]   \n",
      "2  A2I8LFSN2IS5EO  B00002243X            Chris    [0, 0]   \n",
      "3  A3GT2EWQSO45ZG  B00002243X           DeusEx  [19, 19]   \n",
      "4  A3ESWJPAVRPWB4  B00002243X     E. Hernandez    [0, 0]   \n",
      "\n",
      "                                          reviewText  overall  \\\n",
      "0  I needed a set of jumper cables for my new car...      5.0   \n",
      "1  These long cables work fine for my truck, but ...      4.0   \n",
      "2  Can't comment much on these since they have no...      5.0   \n",
      "3  I absolutley love Amazon!!!  For the price of ...      5.0   \n",
      "4  I purchased the 12' feet long cable set and th...      5.0   \n",
      "\n",
      "                                      summary  unixReviewTime   reviewTime  \n",
      "0  Work Well - Should Have Bought Longer Ones      1313539200  08 17, 2011  \n",
      "1                            Okay long cables      1315094400   09 4, 2011  \n",
      "2                  Looks and feels heavy Duty      1374710400  07 25, 2013  \n",
      "3       Excellent choice for Jumper Cables!!!      1292889600  12 21, 2010  \n",
      "4      Excellent, High Quality Starter Cables      1341360000   07 4, 2012  \n",
      "(20473, 9)\n",
      "Index(['reviewerID', 'asin', 'reviewerName', 'helpful', 'reviewText',\n",
      "       'overall', 'summary', 'unixReviewTime', 'reviewTime'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.head())\n",
    "print(df.shape)\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to set up a sentiment analysis the first step we need to do is cleaning the text to perform a better analysis on it.  Let's try to write a function to perform some of the initial scrubbing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(series):\n",
    "    '''Cleaning text for sentiment analysis'''\n",
    "    \n",
    "    clean = series\n",
    "    \n",
    "    # Make everything lowercase\n",
    "    clean = clean.apply(lambda x: x.lower())\n",
    "    \n",
    "    # Remove punctuation - the None says that we did not add any information to 'translate' (replace)\n",
    "    # the string.punctuation provides a list of all the possible punctuation we want to remove\n",
    "    clean = clean.apply(lambda x: x.translate(str.maketrans('','', string.punctuation)))\n",
    "    \n",
    "    # Remove numbers\n",
    "    clean = clean.apply(lambda x: x.translate(str.maketrans('','', string.digits)))\n",
    "    \n",
    "    # Remove a few common stop words\n",
    "    stop_words = ['a','able','about','across','after','all','almost','also','am','among','an','and','any','are',\n",
    "                  'as','at','be','because','been','but','by','can','cannot','could','dear','did','do','does','either',\n",
    "                  'else','ever','every','for','from','get','got','had','has','have','he','her','hers','him','his','how',\n",
    "                  'however','i','im','if','in','into','is','it','its','ive','just','least','let','like','likely','may','me',\n",
    "                  'might','most','must','my','neither','no','nor','not','of','off','often','on','only','or','other','our','own',\n",
    "                  'rather','said','say','says','she','should','since','so','some','than','that','the','their','them','then',\n",
    "                  'there','these','they','this','tis','to','too','twas','us','wants','was','we','were','what','when','where',\n",
    "                  'which','while','who','whom','why','will','with','would','yet','you','your']\n",
    "    clean = clean.apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))\n",
    "    \n",
    "    # use the imported stop words from sklearn\n",
    "    stop = text.ENGLISH_STOP_WORDS\n",
    "    clean = clean.apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
    "    \n",
    "    return clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              reviewText  \\\n",
      "0      needed set jumper cables new car good reviews ...   \n",
      "1      long cables work fine truck quality little sha...   \n",
      "2      comment used come update review issues use bui...   \n",
      "3      absolutley love amazon price set cheap booster...   \n",
      "4      purchased feet long cable set arrived retail c...   \n",
      "5      jumper cables heavy duty easy store containers...   \n",
      "6      bought k suburban plenty length rear ended usi...   \n",
      "7      good motorized vehicles running semi farm equi...   \n",
      "8      coleman cable feet heavyduty truck auto batter...   \n",
      "9      old car bound need set gave old ones boss truc...   \n",
      "10     use jumper cables time year usually elses car ...   \n",
      "11     jumper cables real jumper cables jumper cables...   \n",
      "12     guys stops helps people need pro recovery guy ...   \n",
      "13     arent best cables buy youll electrical welding...   \n",
      "14     hard pure copper cabled jumper cables add gave...   \n",
      "15     insurance policy land rover ounce prevention w...   \n",
      "16     product serves purpose use hauling canoes cabi...   \n",
      "17     hitch extender good kayak transport allows sec...   \n",
      "18                                                         \n",
      "19     package arrived bit ragged easy install takes ...   \n",
      "20     exactly needed transporting fishing kayak bed ...   \n",
      "21     bought haul kayaks works great given stars com...   \n",
      "22     owned trucks years gotten long lumber problems...   \n",
      "23     anybody car clean washes car sits outside park...   \n",
      "24      product supposed real happy quality construction   \n",
      "25     buy product stick detaling microfiber towels v...   \n",
      "26     original california car duster works great tou...   \n",
      "27     car enthusiasts liked hours detailing work des...   \n",
      "28     takes dust car leaving streaking report brands...   \n",
      "29     really best car duster opinion used cheap fall...   \n",
      "...                                                  ...   \n",
      "20443  great kit great price usually kit accessory sh...   \n",
      "20444  ah goofy fun jazz car fun playing colors cours...   \n",
      "20445  basically led lights nice addition dash illumi...   \n",
      "20446  weve product figured itd interesting try prett...   \n",
      "20447  ok light nut fabricate led light painting tool...   \n",
      "20448  nice addition interior hot teens carwell wayno...   \n",
      "20449  probably install inside cabin vehicle used ill...   \n",
      "20450  awesome idea board turns stove handy versatile...   \n",
      "20451  work surface nice size built nice add working ...   \n",
      "20452  small kitchen using stove work surface way lif...   \n",
      "20453  youve needed little work space kitchen want ch...   \n",
      "20454  thinlight weightdurablebeautifulthis larger st...   \n",
      "20455  wife cared kitchen home laid mobile home doubl...   \n",
      "20456  live sunny climate week evenings dusk drive ha...   \n",
      "20457  interesting product definitely pluses minuses ...   \n",
      "20458  actually works pretty yellow really makes thin...   \n",
      "20459  vision visor car visors day time night time su...   \n",
      "20460  afraid sold exactly falls short areasit really...   \n",
      "20461  good sunshade driving bright sun polarizer job...   \n",
      "20462  received visor set free review purposes receiv...   \n",
      "20463  keeps bugs mouth looking badass tubluar design...   \n",
      "20464  use time ride order hand didnt think work ways...   \n",
      "20465  think cool sweet looking half skull mask thats...   \n",
      "20466  honestly dont think worth fun ok bought motorc...   \n",
      "20467  material warm barley breaks wind cold day pret...   \n",
      "20468  bought past year gifts friends club brothers r...   \n",
      "20469  ok admit price item expectations unfairly high...   \n",
      "20470  love skull face mask makes outstand rest fello...   \n",
      "20471  mask course described halfface long protection...   \n",
      "20472  good light weight cool nights rain half helmet...   \n",
      "\n",
      "                                                 summary  \n",
      "0                                work bought longer ones  \n",
      "1                                       okay long cables  \n",
      "2                                 looks feels heavy duty  \n",
      "3                         excellent choice jumper cables  \n",
      "4                  excellent high quality starter cables  \n",
      "5                                         compact strong  \n",
      "6                                            nice cables  \n",
      "7                                           cars pickups  \n",
      "8      coleman cable feet heavyduty truck auto batter...  \n",
      "9                                                  beefy  \n",
      "10                                   fine consumer grade  \n",
      "11                               jumper cables real deal  \n",
      "12                                         great quality  \n",
      "13                                 sure theyre really ga  \n",
      "14                                    plated copper wire  \n",
      "15                                     stars havent used  \n",
      "16                                              expected  \n",
      "17                       extendatruck truck bed extender  \n",
      "18                               brainer easy use sturdy  \n",
      "19                                          easy install  \n",
      "20                                                  love  \n",
      "21                                            great idea  \n",
      "22                good design solid construction compact  \n",
      "23                                   perfect outside car  \n",
      "24                                               average  \n",
      "25                                              supposed  \n",
      "26                                      great pride ride  \n",
      "27                                      gentle effective  \n",
      "28                                                        \n",
      "29                                       best car duster  \n",
      "...                                                  ...  \n",
      "20443                             funky car lighting kit  \n",
      "20444                  trick ride love kit works indoors  \n",
      "20445                                       bright flaws  \n",
      "20446                                interesting product  \n",
      "20447                                        simple plug  \n",
      "20448                                             tricks  \n",
      "20449      super cool super easy installed truck toolbox  \n",
      "20450                     turn stove giant cutting board  \n",
      "20451                       work surface nice size built  \n",
      "20452                            wonderful kitchen asset  \n",
      "20453                              beauty meets function  \n",
      "20454                          love home kitchen counter  \n",
      "20455        additional counter space little careful use  \n",
      "20456                              stops glare sun night  \n",
      "20457                                        good people  \n",
      "20458                                          great suv  \n",
      "20459                                   works situations  \n",
      "20460                           promises size limitation  \n",
      "20461                                          flipshade  \n",
      "20462                  works limitations want compromise  \n",
      "20463                                         great item  \n",
      "20464                                stretchable tubular  \n",
      "20465                           wanna look cool buy love  \n",
      "20466                                        ok fo money  \n",
      "20467                                              ehhhh  \n",
      "20468                            excellent quality price  \n",
      "20469      light weight neck face cover whimsical design  \n",
      "20470                          love ride skull face mask  \n",
      "20471                              great neck protection  \n",
      "20472                                          face mask  \n",
      "\n",
      "[20473 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "df['reviewText'] = clean_text(df.reviewText)\n",
    "df['summary'] = clean_text(df.summary)\n",
    "print(df[['reviewText', 'summary']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like the summary data is much cleaner - so we will use that for the initial training of the model.  What the countvectorizer is doing is 'tokenizing the documents and count the occurrences of token and returning them as a sparse matrix'. Essentially, getting a frequency count for the words left in the dataset, returning a count matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20473, 6735)\n"
     ]
    }
   ],
   "source": [
    "cv = CountVectorizer()\n",
    "cv.fit(df.summary)\n",
    "X = cv.transform(df.summary)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullwords = pd.DataFrame(list(zip(cv.get_feature_names(), sum(X.toarray()))), \n",
    "             columns=['Word','Frequency']).sort_values(by='Frequency', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14331, 6735)\n",
      "(6142, 6735)\n",
      "(14331,)\n",
      "(6142,)\n"
     ]
    }
   ],
   "source": [
    "# split up data\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, df.overall, test_size=0.3)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_train.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_model(clf, x, y, crossval=False, cv=5, cm=False):\n",
    "    # Run baseline regression\n",
    "    fit = clf.fit(x, y)\n",
    "\n",
    "    # Predict the model\n",
    "    pred_y = clf.predict(x)\n",
    "    \n",
    "    if crossval == True:\n",
    "        # Average score\n",
    "        avscore = cross_val_score(clf, x, y, cv=cv)\n",
    "        print('Baseline Model has a average cv score of', round(avscore.mean(), 2) * 100,\"% accuracy score\")\n",
    "    \n",
    "    score = clf.score(x,y)\n",
    "    print('Baseline Model has a score of: {}'.format(score))\n",
    "    \n",
    "    # Get the Precision, Recall, and F1 score\n",
    "    print(classification_report(y, pred_y))\n",
    "    \n",
    "    if cm==True:\n",
    "        print('Confusion Matrix:')\n",
    "        print(confusion_matrix(y,pred_y))\n",
    "    \n",
    "    return fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Model has a average cv score of 70.0 % accuracy score\n",
      "Baseline Model has a score of: 0.7547275137813132\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.91      0.28      0.43       370\n",
      "         2.0       0.87      0.19      0.32       409\n",
      "         3.0       0.77      0.34      0.47      1000\n",
      "         4.0       0.76      0.23      0.35      2771\n",
      "         5.0       0.75      0.99      0.85      9781\n",
      "\n",
      "   micro avg       0.75      0.75      0.75     14331\n",
      "   macro avg       0.81      0.41      0.48     14331\n",
      "weighted avg       0.76      0.75      0.70     14331\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "lr = baseline_model(LogisticRegression(), X_train, Y_train, crossval=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Model has a average cv score of 68.0 % accuracy score\n",
      "Baseline Model has a score of: 0.7191403251692136\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      0.00      0.01       370\n",
      "         2.0       1.00      0.01      0.01       409\n",
      "         3.0       0.72      0.08      0.14      1000\n",
      "         4.0       0.64      0.19      0.30      2771\n",
      "         5.0       0.72      0.99      0.84      9781\n",
      "\n",
      "   micro avg       0.72      0.72      0.72     14331\n",
      "   macro avg       0.82      0.25      0.26     14331\n",
      "weighted avg       0.72      0.72      0.64     14331\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes\n",
    "nb = baseline_model(BernoulliNB(), X_train, Y_train, crossval=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Model has a average cv score of 68.0 % accuracy score\n",
      "Baseline Model has a score of: 0.68571627939432\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      0.01      0.02       370\n",
      "         2.0       0.88      0.02      0.03       409\n",
      "         3.0       0.62      0.01      0.03      1000\n",
      "         4.0       0.78      0.01      0.02      2771\n",
      "         5.0       0.69      1.00      0.81      9781\n",
      "\n",
      "   micro avg       0.69      0.69      0.69     14331\n",
      "   macro avg       0.79      0.21      0.18     14331\n",
      "weighted avg       0.71      0.69      0.56     14331\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree\n",
    "dt = baseline_model(DecisionTreeClassifier(max_features='sqrt', max_depth=10), X_train, Y_train, crossval=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Model has a average cv score of 69.0 % accuracy score\n",
      "Baseline Model has a score of: 0.7155118275068034\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.95      0.16      0.27       370\n",
      "         2.0       1.00      0.12      0.22       409\n",
      "         3.0       0.91      0.18      0.30      1000\n",
      "         4.0       0.94      0.07      0.13      2771\n",
      "         5.0       0.71      1.00      0.83      9781\n",
      "\n",
      "   micro avg       0.72      0.72      0.72     14331\n",
      "   macro avg       0.90      0.31      0.35     14331\n",
      "weighted avg       0.78      0.72      0.62     14331\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rfc = baseline_model(RandomForestClassifier(max_features='sqrt', max_depth=50), X_train, Y_train, crossval=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the data above it appears that the best model to use going forwards is going the Random Forest Classifier.  It the best accuracy combined with the best recall scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6846304135460762"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the random forest classifier\n",
    "rfc.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's drop the features that have very low frequencies.  Figure out how to use n-grams and normalize words like loved or loving to love."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20473, 1000)\n"
     ]
    }
   ],
   "source": [
    "# by setting the max_features in the CountVectorizer we can select the most frequent words in the file\n",
    "cv_max = CountVectorizer(max_features=1000, ngram_range=(1,2))\n",
    "cv_max.fit(df.summary)\n",
    "X_max = cv_max.transform(df.summary)\n",
    "print(X_max.shape)\n",
    "Xm_train, Xm_test, Ym_train, Ym_test = train_test_split(X_max, df.overall, test_size=0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Word  Frequency\n",
      "342    great       3294\n",
      "317     good       2057\n",
      "974    works       1663\n",
      "656  product       1089\n",
      "572     nice        742\n"
     ]
    }
   ],
   "source": [
    "topwords = pd.DataFrame(list(zip(cv_max.get_feature_names(), sum(X_max.toarray()))), \n",
    "             columns=['Word','Frequency']).sort_values(by='Frequency', ascending=False)\n",
    "print(topwords.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
      "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
      "          tol=0.0001, verbose=0, warm_start=False\n",
      "Baseline Model has a average cv score of 69.0 % accuracy score\n",
      "Baseline Model has a score of: 0.7146744818924011\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.81      0.18      0.29       377\n",
      "         2.0       0.77      0.08      0.14       438\n",
      "         3.0       0.67      0.20      0.30      1000\n",
      "         4.0       0.57      0.15      0.24      2791\n",
      "         5.0       0.72      0.98      0.83      9725\n",
      "\n",
      "   micro avg       0.71      0.71      0.71     14331\n",
      "   macro avg       0.71      0.32      0.36     14331\n",
      "weighted avg       0.69      0.71      0.64     14331\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True\n",
      "Baseline Model has a average cv score of 67.0 % accuracy score\n",
      "Baseline Model has a score of: 0.7019049612727654\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.50      0.21      0.30       377\n",
      "         2.0       0.41      0.11      0.17       438\n",
      "         3.0       0.51      0.25      0.34      1000\n",
      "         4.0       0.48      0.23      0.32      2791\n",
      "         5.0       0.74      0.93      0.82      9725\n",
      "\n",
      "   micro avg       0.70      0.70      0.70     14331\n",
      "   macro avg       0.53      0.35      0.39     14331\n",
      "weighted avg       0.66      0.70      0.66     14331\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features='sqrt', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'\n",
      "Baseline Model has a average cv score of 62.0 % accuracy score\n",
      "Baseline Model has a score of: 0.8552787663107948\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.84      0.60      0.70       377\n",
      "         2.0       0.80      0.62      0.70       438\n",
      "         3.0       0.87      0.67      0.76      1000\n",
      "         4.0       0.86      0.60      0.71      2791\n",
      "         5.0       0.86      0.97      0.91      9725\n",
      "\n",
      "   micro avg       0.86      0.86      0.86     14331\n",
      "   macro avg       0.85      0.69      0.75     14331\n",
      "weighted avg       0.86      0.86      0.85     14331\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='sqrt', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=None,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False\n",
      "Baseline Model has a average cv score of 64.0 % accuracy score\n",
      "Baseline Model has a score of: 0.8468355313655711\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.90      0.54      0.67       377\n",
      "         2.0       0.85      0.56      0.67       438\n",
      "         3.0       0.89      0.62      0.73      1000\n",
      "         4.0       0.87      0.56      0.68      2791\n",
      "         5.0       0.84      0.98      0.90      9725\n",
      "\n",
      "   micro avg       0.85      0.85      0.85     14331\n",
      "   macro avg       0.87      0.65      0.73     14331\n",
      "weighted avg       0.85      0.85      0.83     14331\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "classifiers=[LogisticRegression(), \n",
    "             BernoulliNB(),\n",
    "             DecisionTreeClassifier(max_features='sqrt'),\n",
    "             RandomForestClassifier(max_features='sqrt')]\n",
    "for clf in classifiers:\n",
    "    print(str(clf).strip('()'))\n",
    "    baseline_model(clf, Xm_train, Ym_train, crossval=True)\n",
    "    print('--'*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's go one step further and apply a Term Frequency - Inverse Document Frequency transform to the count matrix.  The term frequency part means that the frequencies will be divided by the total number of words in the set.  The inverse document frequency part is to downscale the weights of words that occur the most frequently in the matrix. The goal of using tf-idf instead of the raw frequencies (count matrix) of occurrence of a token in a given document is to scale down the impact of tokens that occur very frequently in a given corpus and that are hence empirically less informative than features that occur in a small fraction of the training corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tfidf transform\n",
    "tfidf = TfidfTransformer(norm='l2')\n",
    "transformedX = tfidf.fit_transform(X_max)\n",
    "\n",
    "# resplit\n",
    "Xt_train, Xt_test, Yt_train, Yt_test = train_test_split(X_max, df.overall, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
      "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
      "          tol=0.0001, verbose=0, warm_start=False\n",
      "Baseline Model has a average cv score of 69.0 % accuracy score\n",
      "Baseline Model has a score of: 0.7191403251692136\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.76      0.18      0.29       369\n",
      "         2.0       0.66      0.08      0.14       450\n",
      "         3.0       0.64      0.23      0.34      1009\n",
      "         4.0       0.59      0.15      0.24      2763\n",
      "         5.0       0.73      0.98      0.84      9740\n",
      "\n",
      "   micro avg       0.72      0.72      0.72     14331\n",
      "   macro avg       0.68      0.33      0.37     14331\n",
      "weighted avg       0.69      0.72      0.65     14331\n",
      "\n",
      "Confusion Matrix:\n",
      "[[  67    6   17   14  265]\n",
      " [  12   35   33   27  343]\n",
      " [   4    6  237   95  667]\n",
      " [   3    4   54  423 2279]\n",
      " [   2    2   29  163 9544]]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True\n",
      "Baseline Model has a average cv score of 67.0 % accuracy score\n",
      "Baseline Model has a score of: 0.7053939013327751\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.55      0.19      0.29       369\n",
      "         2.0       0.41      0.12      0.19       450\n",
      "         3.0       0.55      0.28      0.37      1009\n",
      "         4.0       0.48      0.25      0.33      2763\n",
      "         5.0       0.74      0.93      0.82      9740\n",
      "\n",
      "   micro avg       0.71      0.71      0.71     14331\n",
      "   macro avg       0.55      0.35      0.40     14331\n",
      "weighted avg       0.66      0.71      0.66     14331\n",
      "\n",
      "Confusion Matrix:\n",
      "[[  71    6   22   17  253]\n",
      " [  16   56   45   31  302]\n",
      " [   5   14  280  126  584]\n",
      " [  12   13   73  691 1974]\n",
      " [  25   46   85  573 9011]]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features='sqrt', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'\n",
      "Baseline Model has a average cv score of 62.0 % accuracy score\n",
      "Baseline Model has a score of: 0.8600237247924081\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.81      0.64      0.72       369\n",
      "         2.0       0.82      0.60      0.69       450\n",
      "         3.0       0.84      0.70      0.76      1009\n",
      "         4.0       0.87      0.61      0.72      2763\n",
      "         5.0       0.86      0.97      0.91      9740\n",
      "\n",
      "   micro avg       0.86      0.86      0.86     14331\n",
      "   macro avg       0.84      0.70      0.76     14331\n",
      "weighted avg       0.86      0.86      0.85     14331\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 237    3    4    4  121]\n",
      " [  20  270   11   11  138]\n",
      " [   7   18  702   17  265]\n",
      " [  11   18   63 1681  990]\n",
      " [  16   19   57  213 9435]]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='sqrt', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False\n",
      "Baseline Model has a average cv score of 64.0 % accuracy score\n",
      "Baseline Model has a score of: 0.8515107110459842\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.85      0.57      0.69       369\n",
      "         2.0       0.86      0.54      0.66       450\n",
      "         3.0       0.88      0.63      0.73      1009\n",
      "         4.0       0.88      0.57      0.69      2763\n",
      "         5.0       0.85      0.98      0.91      9740\n",
      "\n",
      "   micro avg       0.85      0.85      0.85     14331\n",
      "   macro avg       0.86      0.66      0.73     14331\n",
      "weighted avg       0.85      0.85      0.84     14331\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 212    8    6   11  132]\n",
      " [  14  241   14   21  160]\n",
      " [   5   14  633   51  306]\n",
      " [   6   11   37 1563 1146]\n",
      " [  12    6   33  135 9554]]\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for clf in classifiers:\n",
    "    print(str(clf).strip('()'))\n",
    "    baseline_model(clf, Xt_train, Yt_train, crossval=True, cm=True)\n",
    "    print('--'*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not much change using the Tfidf, ngrams (1,2), max_features=1000, and normalization (both l1 and l2).  Since we are creating a sentiment analysis, let's code the outcome variable as a binary to try and capture more of the sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.0    13928\n",
      "4.0     3967\n",
      "3.0     1430\n",
      "2.0      606\n",
      "1.0      542\n",
      "Name: overall, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.overall.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there are so many 5.0 ratings we will combine 4.0 and 5.0 as good, and the rest will be considered bad.  This binary coding assumes that 3s are bad, but with such an imbalance between goods and bads I feel this will be okay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
      "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
      "          tol=0.0001, verbose=0, warm_start=False\n",
      "Baseline Model has a average cv score of 89.0 % accuracy score\n",
      "Baseline Model has a score of: 0.8972158258321122\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.25      0.38      1809\n",
      "           1       0.90      0.99      0.94     12522\n",
      "\n",
      "   micro avg       0.90      0.90      0.90     14331\n",
      "   macro avg       0.85      0.62      0.66     14331\n",
      "weighted avg       0.89      0.90      0.87     14331\n",
      "\n",
      "Confusion Matrix:\n",
      "[[  451  1358]\n",
      " [  115 12407]]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True\n",
      "Baseline Model has a average cv score of 88.0 % accuracy score\n",
      "Baseline Model has a score of: 0.8928895401577001\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.32      0.43      1809\n",
      "           1       0.91      0.98      0.94     12522\n",
      "\n",
      "   micro avg       0.89      0.89      0.89     14331\n",
      "   macro avg       0.78      0.65      0.69     14331\n",
      "weighted avg       0.88      0.89      0.88     14331\n",
      "\n",
      "Confusion Matrix:\n",
      "[[  587  1222]\n",
      " [  313 12209]]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features='sqrt', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'\n",
      "Baseline Model has a average cv score of 85.0 % accuracy score\n",
      "Baseline Model has a score of: 0.949619705533459\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.69      0.78      1809\n",
      "           1       0.96      0.99      0.97     12522\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     14331\n",
      "   macro avg       0.92      0.84      0.87     14331\n",
      "weighted avg       0.95      0.95      0.95     14331\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 1252   557]\n",
      " [  165 12357]]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='sqrt', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False\n",
      "Baseline Model has a average cv score of 87.0 % accuracy score\n",
      "Baseline Model has a score of: 0.9448747470518456\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.62      0.74      1809\n",
      "           1       0.95      0.99      0.97     12522\n",
      "\n",
      "   micro avg       0.94      0.94      0.94     14331\n",
      "   macro avg       0.93      0.81      0.85     14331\n",
      "weighted avg       0.94      0.94      0.94     14331\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 1127   682]\n",
      " [  108 12414]]\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# make outcome a binary\n",
    "binary = np.where(df.overall >= 4, 1, 0)\n",
    "\n",
    "# resplit\n",
    "Xtb_train, Xtb_test, Ytb_train, Ytb_test = train_test_split(X_max, binary, test_size=0.3)\n",
    "\n",
    "# re-run models\n",
    "for clf in classifiers:\n",
    "    print(str(clf).strip('()'))\n",
    "    baseline_model(clf, Xtb_train, Ytb_train, crossval=True, cm=True)\n",
    "    print('--'*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Model has a average cv score of 87.0 % accuracy score\n",
      "Baseline Model has a score of: 0.9457818714674482\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.64      0.75      1809\n",
      "           1       0.95      0.99      0.97     12522\n",
      "\n",
      "   micro avg       0.95      0.95      0.95     14331\n",
      "   macro avg       0.93      0.81      0.86     14331\n",
      "weighted avg       0.94      0.95      0.94     14331\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 1151   658]\n",
      " [  119 12403]]\n"
     ]
    }
   ],
   "source": [
    "rfc = baseline_model(RandomForestClassifier(), Xtb_train, Ytb_train, crossval=True, cm=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8650276782806904\n",
      "col_0    0     1   All\n",
      "row_0                 \n",
      "0      207   562   769\n",
      "1      267  5106  5373\n",
      "All    474  5668  6142\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.27      0.33       769\n",
      "           1       0.90      0.95      0.92      5373\n",
      "\n",
      "   micro avg       0.87      0.87      0.87      6142\n",
      "   macro avg       0.67      0.61      0.63      6142\n",
      "weighted avg       0.84      0.87      0.85      6142\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(rfc.score(Xtb_test, Ytb_test))\n",
    "table = pd.crosstab(Ytb_test, rfc.predict(Xtb_test), margins=True)\n",
    "print(table)\n",
    "print(classification_report(Ytb_test, rfc.predict(Xtb_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the parameters set above we have a 87% accuracy in the test set.  We are very good at predicting good values but struggle more with the bads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
