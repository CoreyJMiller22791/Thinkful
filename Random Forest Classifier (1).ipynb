{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Suppress annoying harmless error.\n",
    "warnings.filterwarnings(action=\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2015 = pd.read_csv(\n",
    "    'LoanStats3d.csv',\n",
    "    skipinitialspace=True,\n",
    "    header=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2015.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I believe the original data I saw (for a brief second until the kernal crashed and I was unable to reload the data) had 111 columns and actually had id information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "categorical = y2015.select_dtypes(include=['object'])\n",
    "\n",
    "for i in categorical:\n",
    "    column = categorical[i]\n",
    "    print(i)\n",
    "    print(column.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Convert ID and Interest Rate to numeric.\n",
    "y2015['id'] = pd.to_numeric(y2015['id'], errors='coerce')\n",
    "y2015['int_rate'] = pd.to_numeric(y2015['int_rate'].str.strip('%'), errors='coerce')\n",
    "\n",
    "# Drop other columns with many unique variables\n",
    "y2015.drop(['url', 'emp_title', 'zip_code', 'earliest_cr_line', 'revol_util',\n",
    "            'sub_grade', 'addr_state', 'desc'], 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2015 = y2015[:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import ensemble\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "rfc = ensemble.RandomForestClassifier()\n",
    "X = y2015.drop('loan_status', 1)\n",
    "Y = y2015['loan_status']\n",
    "X = pd.get_dummies(X)\n",
    "X = X.dropna(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         Importance\n",
      "out_prncp_inv              0.196462\n",
      "recoveries                 0.122315\n",
      "out_prncp                  0.120141\n",
      "collection_recovery_fee    0.061705\n",
      "total_rec_prncp            0.060442\n",
      "last_pymnt_d_Sep-2018      0.052286\n",
      "next_pymnt_d_Oct-2018      0.048439\n",
      "last_pymnt_amnt            0.043433\n",
      "total_pymnt                0.032642\n",
      "term_ 60 months            0.027453\n"
     ]
    }
   ],
   "source": [
    "rfc.fit(X, Y)\n",
    "\n",
    "# get feature importances\n",
    "frank=rfc.feature_importances_\n",
    "frankdf = pd.DataFrame(frank, index=X.columns, columns=['Importance']).sort_values('Importance', ascending=False)\n",
    "\n",
    "print(frankdf.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.83722452 0.06901664 0.04370485 0.02703175]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "sklearnPCA = PCA(n_components = 4)\n",
    "transformed = sklearnPCA.fit_transform(X)\n",
    "\n",
    "features = sklearnPCA.explained_variance_ratio_ \n",
    "print(features)\n",
    "\n",
    "#print(sklearnPCA.components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.54381174, 0.53953742, 0.54108093, 0.5376505 , 0.53873189,\n",
       "       0.53889812, 0.54206939, 0.54131142, 0.542868  , 0.54517171])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(rfc, transformed, Y, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.95383739, 0.94913564, 0.93619396, 0.92429531, 0.88793636,\n",
       "       0.90102114, 0.96019853, 0.97112119, 0.97033677, 0.97040802])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA(n_components = 15)\n",
    "x1 = pca.fit_transform(X)\n",
    "cross_val_score(rfc, x1, Y, cv=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen in the dataframe above of the feature ranks we can select the most important features to build the model on.  Using that list would (hopefully) allow us to drop the payment amount and outstanding principal and still maintain a cross validation of larger than .90.  \n",
    "\n",
    "This data set is too large to continue to play around with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
