{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Neural Networks - Playing with layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "import scipy\n",
    "import sklearn\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to load in chunks: 276.84537\n"
     ]
    }
   ],
   "source": [
    "#load data in chunks\n",
    "t0=time.time()\n",
    "df=pd.DataFrame()\n",
    "for chunk in pd.read_csv('https://media.githubusercontent.com/media/MuseumofModernArt/collection/master/Artworks.csv', \n",
    "                         chunksize=500000, \n",
    "                         low_memory=False):\n",
    "    df = pd.concat([df,chunk])\n",
    "t1=time.time()\n",
    "print('Time to load in chunks: {:.5f}'.format(t1-t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(135804, 29)\n",
      "Index(['Title', 'Artist', 'ConstituentID', 'ArtistBio', 'Nationality',\n",
      "       'BeginDate', 'EndDate', 'Gender', 'Date', 'Medium', 'Dimensions',\n",
      "       'CreditLine', 'AccessionNumber', 'Classification', 'Department',\n",
      "       'DateAcquired', 'Cataloged', 'ObjectID', 'URL', 'ThumbnailURL',\n",
      "       'Circumference (cm)', 'Depth (cm)', 'Diameter (cm)', 'Height (cm)',\n",
      "       'Length (cm)', 'Weight (kg)', 'Width (cm)', 'Seat Height (cm)',\n",
      "       'Duration (sec.)'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Artist Nationality  Gender  Date             Department  \\\n",
      "0               Otto Wagner  (Austrian)  (Male)  1896  Architecture & Design   \n",
      "1  Christian de Portzamparc    (French)  (Male)  1987  Architecture & Design   \n",
      "2                Emil Hoppe  (Austrian)  (Male)  1903  Architecture & Design   \n",
      "3           Bernard Tschumi          ()  (Male)  1980  Architecture & Design   \n",
      "4                Emil Hoppe  (Austrian)  (Male)  1903  Architecture & Design   \n",
      "\n",
      "  DateAcquired   URL  ThumbnailURL  Height (cm)  Width (cm)  \n",
      "0   1996-04-09  True          True      48.6000    168.9000  \n",
      "1   1995-01-17  True          True      40.6401     29.8451  \n",
      "2   1997-01-15  True          True      34.3000     31.8000  \n",
      "3   1995-01-17  True          True      50.8000     50.8000  \n",
      "4   1997-01-15  True          True      38.4000     19.1000  \n",
      "(106031, 10)\n"
     ]
    }
   ],
   "source": [
    "# Select Columns.\n",
    "df = df[['Artist', 'Nationality', 'Gender', 'Date', 'Department',\n",
    "                    'DateAcquired', 'URL', 'ThumbnailURL', 'Height (cm)', 'Width (cm)']]\n",
    "\n",
    "# Convert URL's to booleans.\n",
    "df['URL'] = df['URL'].notnull()\n",
    "df['ThumbnailURL'] = df['ThumbnailURL'].notnull()\n",
    "\n",
    "# Drop films and some other tricky rows.\n",
    "df = df[df['Department']!='Film']\n",
    "df = df[df['Department']!='Media and Performance Art']\n",
    "df = df[df['Department']!='Fluxus Collection']\n",
    "\n",
    "# Drop missing data.\n",
    "df = df.dropna()\n",
    "print(df.head())\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['DateAcquired'] = pd.to_datetime(df.DateAcquired)\n",
    "df['YearAcquired'] = df.DateAcquired.dt.year\n",
    "df['YearAcquired'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Remove multiple nationalities, genders, and artists.\n",
    "df.loc[df['Gender'].str.contains('\\) \\('), 'Gender'] = '\\(multiple_persons\\)'\n",
    "df.loc[df['Nationality'].str.contains('\\) \\('), 'Nationality'] = '\\(multiple_nationalities\\)'\n",
    "df.loc[df['Artist'].str.contains(','), 'Artist'] = 'Multiple_Artists'\n",
    "\n",
    "\n",
    "# Convert dates to start date, cutting down number of distinct examples.\n",
    "df['Date'] = pd.Series(df.Date.str.extract(\n",
    "    '([0-9]{4})', expand=False))[:-1]\n",
    "\n",
    "# Final column drops and NA drop.\n",
    "X = df.drop(['Department', 'DateAcquired', 'Artist', 'Nationality', 'Date'], 1)\n",
    "\n",
    "# Create dummies separately.\n",
    "artists = pd.get_dummies(df.Artist)\n",
    "nationalities = pd.get_dummies(df.Nationality)\n",
    "dates = pd.get_dummies(df.Date)\n",
    "\n",
    "# Concat with other variables, but artists slows this wayyyyy down so we'll keep it out for now\n",
    "X = pd.get_dummies(X, sparse=True)\n",
    "X = pd.concat([X, nationalities, dates], axis=1)\n",
    "Y = df.Department\n",
    "\n",
    "# sample down to try and get the model to run\n",
    "XY = pd.concat([X, df.Department], 1)\n",
    "XY = XY.sample(frac=0.1, random_state=42)\n",
    "Xsam = XY.drop('Department', 1)\n",
    "Ysam = XY.Department"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 53.14585\n"
     ]
    }
   ],
   "source": [
    "# Alright! We've done our prep, let's build the model.\n",
    "# Neural networks are hugely computationally intensive.\n",
    "# This may take several minutes to run.\n",
    "\n",
    "# Import the model.\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "t0=time.time()\n",
    "# Establish and fit the model, with a single, 1000 + perceptron layer.\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(1000,), random_state=42)\n",
    "mlp.fit(Xsam, Ysam)\n",
    "t1=time.time()\n",
    "print(\"Time: {:0.5f}\".format(t1-t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:  0.6134112986890503\n",
      "Prints & Illustrated Books    0.526266\n",
      "Photography                   0.228992\n",
      "Architecture & Design         0.111195\n",
      "Drawings                      0.100821\n",
      "Painting & Sculpture          0.032727\n",
      "Name: Department, dtype: float64\n",
      "[0.61168709 0.60508954 0.42149929 0.61367925 0.60339943]\n",
      "Time: 147.44063\n"
     ]
    }
   ],
   "source": [
    "t0=time.time()\n",
    "print('Score: ',mlp.score(Xsam, Ysam))\n",
    "print(Ysam.value_counts()/len(Ysam))\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "print(cross_val_score(mlp, Xsam, Ysam, cv=5))\n",
    "t1=time.time()\n",
    "print(\"Time: {:0.5f}\".format(t1-t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Play around"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 39.14951\n"
     ]
    }
   ],
   "source": [
    "# 10 layers of 100\n",
    "t0=time.time()\n",
    "# 10 by 100\n",
    "mlp100 = MLPClassifier(hidden_layer_sizes=(100, 100, 100, 100, 100, \n",
    "                                        100, 100, 100, 100, 100,), \n",
    "                    random_state=42)\n",
    "mlp100.fit(Xsam, Ysam)\n",
    "t1=time.time()\n",
    "print(\"Time: {:0.5f}\".format(t1-t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:  0.544845798358955\n",
      "Prints & Illustrated Books    0.526266\n",
      "Photography                   0.228992\n",
      "Architecture & Design         0.111195\n",
      "Drawings                      0.100821\n",
      "Painting & Sculpture          0.032727\n",
      "Name: Department, dtype: float64\n",
      "[0.65739868 0.66776626 0.65912306 0.63584906 0.62511804]\n",
      "Time: 363.08619\n"
     ]
    }
   ],
   "source": [
    "t0=time.time()\n",
    "print('Score: ',mlp100.score(Xsam, Ysam))\n",
    "print(Ysam.value_counts()/len(Ysam))\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "print(cross_val_score(mlp100, Xsam, Ysam, cv=5))\n",
    "t1=time.time()\n",
    "print(\"Time: {:0.5f}\".format(t1-t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 10.43977\n"
     ]
    }
   ],
   "source": [
    "# logistic\n",
    "t0=time.time()\n",
    "# logistic \n",
    "mlplog = MLPClassifier(hidden_layer_sizes=(100, ), \n",
    "                       random_state=42, \n",
    "                       activation='logistic')\n",
    "mlplog.fit(Xsam, Ysam)\n",
    "t1=time.time()\n",
    "print(\"Time: {:0.5f}\".format(t1-t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:  0.5932283316042629\n",
      "Prints & Illustrated Books    0.526266\n",
      "Photography                   0.228992\n",
      "Architecture & Design         0.111195\n",
      "Drawings                      0.100821\n",
      "Painting & Sculpture          0.032727\n",
      "Name: Department, dtype: float64\n",
      "[0.65928369 0.65739868 0.67326733 0.66037736 0.67469311]\n",
      "Time: 82.43266\n"
     ]
    }
   ],
   "source": [
    "t0=time.time()\n",
    "print('Score: ',mlplog.score(Xsam, Ysam))\n",
    "print(Ysam.value_counts()/len(Ysam))\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "print(cross_val_score(mlplog, Xsam, Ysam, cv=5))\n",
    "t1=time.time()\n",
    "print(\"Time: {:0.5f}\".format(t1-t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 9.20899\n"
     ]
    }
   ],
   "source": [
    "# Serial\n",
    "t0=time.time()\n",
    "\n",
    "mlpserial = MLPClassifier(hidden_layer_sizes=(100, 90, 80, 70, 60,\n",
    "                                           50, 40, 30, 20, 10, ), \n",
    "                       random_state=42, \n",
    "                       activation='logistic')\n",
    "mlpserial.fit(Xsam, Ysam)\n",
    "t1=time.time()\n",
    "print(\"Time: {:0.5f}\".format(t1-t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:  0.5262661510893143\n",
      "Prints & Illustrated Books    0.526266\n",
      "Photography                   0.228992\n",
      "Architecture & Design         0.111195\n",
      "Drawings                      0.100821\n",
      "Painting & Sculpture          0.032727\n",
      "Name: Department, dtype: float64\n",
      "[0.52591894 0.52591894 0.5261669  0.52641509 0.52691218]\n",
      "Prints & Illustrated Books    10603\n",
      "dtype: int64\n",
      "Time: 41.22320\n"
     ]
    }
   ],
   "source": [
    "t0=time.time()\n",
    "print('Score: ',mlpserial.score(Xsam, Ysam))\n",
    "print(Ysam.value_counts()/len(Ysam))\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "print(cross_val_score(mlpserial, Xsam, Ysam, cv=5))\n",
    "print(pd.Series(mlpserial.predict(Xsam)).value_counts())\n",
    "t1=time.time()\n",
    "print(\"Time: {:0.5f}\".format(t1-t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prints & Illustrated Books    10040\n",
       "Architecture & Design           314\n",
       "Painting & Sculpture            249\n",
       "dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(mlp.predict(Xsam)).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prints & Illustrated Books    10040\n",
       "Architecture & Design           314\n",
       "Painting & Sculpture            249\n",
       "dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(mlp100.predict(Xsam)).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prints & Illustrated Books    5599\n",
       "Photography                   4010\n",
       "Architecture & Design          767\n",
       "Painting & Sculpture           227\n",
       "dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(mlplog.predict(Xsam)).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 31.12621\n",
      "Score:  0.5439026690559275\n",
      "Prints & Illustrated Books    0.526266\n",
      "Photography                   0.228992\n",
      "Architecture & Design         0.111195\n",
      "Drawings                      0.100821\n",
      "Painting & Sculpture          0.032727\n",
      "Name: Department, dtype: float64\n",
      "[0.67012253 0.67624882 0.68363979 0.62641509 0.55712937]\n",
      "Prints & Illustrated Books    9834\n",
      "Architecture & Design          657\n",
      "Painting & Sculpture           112\n",
      "dtype: int64\n",
      "Time: 907.47797\n"
     ]
    }
   ],
   "source": [
    "# alpha and logistic\n",
    "t0=time.time()\n",
    "\n",
    "mlpalpha = MLPClassifier(hidden_layer_sizes=(1000, 100, ), \n",
    "                       random_state=42, \n",
    "                       activation='logistic', alpha=1e-2)\n",
    "mlpalpha.fit(Xsam, Ysam)\n",
    "t1=time.time()\n",
    "print(\"Time: {:0.5f}\".format(t1-t0))\n",
    "\n",
    "t0=time.time()\n",
    "print('Score: ',mlpalpha.score(Xsam, Ysam))\n",
    "print(Ysam.value_counts()/len(Ysam))\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "print(cross_val_score(mlpalpha, Xsam, Ysam, cv=5))\n",
    "print(pd.Series(mlpalpha.predict(Xsam)).value_counts())\n",
    "t1=time.time()\n",
    "print(\"Time: {:0.5f}\".format(t1-t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I don't think I have included enough data in the model for the actual predictions to be accurate.  This model runs to slow for me to really play around with the parameters and including more data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
